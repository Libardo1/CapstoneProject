Data Science Specialization - Capstone Project
========================================================
author: bursi
date: 2014-12-02

Final Project Submission

Introduction
========================================================

The purpose of this presentation is to describe the efforts taken by the author for the _Capstone Project_ of the *Data Science Specialization* on [Coursera](http://www.coursera.org). 

The goal of the Capstone Project was to build an algorithm to predict the next word in a sequence of words, based on a data set of newspaper articles, blog posts and twitter tweets. 

The content of the presentation includes descriptions of
- the data processing applied in building a prediction algorithm
- the prediction algorithm itself
- a _Shiny_ app based on the developped prediction algorithm.

Raw data processing
========================================================

The starting point for the project was a large set of text data. In order to build a prediction algorithm, the following data processing steps were performed:
- Choose suitably sized subsets of the text data
- Split the text chunks into sentences and apply filters
- Extract combinations (_n-grams_) of up to 4 words
- Determine the distribution of single words and n-grams
- Filter n-grams with a minimum frequency. For n-grams differing only in the last word, keep only the most frequent one
- Store the filtered n-grams to the hard drive as compressed R-data files to be loaded in the prediction algorithm. 

Prediction algorithm
========================================================

The prediction algorighm which was developed for this project accepts any word sequence as an input and performs the following steps:
- Load the stored n-gram distributions
- Extract the last (up to) 3 words of the input sequence
- Check if a 4-gram can be found with elements 1-3 matching the tail of the input sequence. If this is successful, print the last element of the 4-gram as the prediction for the next word and the algorithm is finished. 
- If not, continue with 3-grams and 2-grams
- If no matching n-gram is found, use the most frequent single word as the prediction. 


Shiny App description
========================================================

The previously described algorithm has been inplemented in an online _Shiny_ [application](http://.). The application accepts any character sequence as input, and upon pressing the "Predict" button starts the prediction algorithm. 

The result and a comment on the type of n-gram used for the prediction are printed in the main panel of the application. 

In order to speed up the application, the n-gram distributions are loaded when the app is launched and therefore don't have to be reloaded every time the "Predict" button is pressed. 
